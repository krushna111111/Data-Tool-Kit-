{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Tool Kit Assignment Theyroticle Question"
      ],
      "metadata": {
        "id": "BgR84ebLpyF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is NumPy, and why is it widely used in Python?\n",
        "\n",
        "   ->1answer-> NumPy, short for Numerical Python, is a fundamental Python library used for numerical computing. Here's a breakdown of what it is and why it's so widely used:   \n",
        "\n",
        "What is NumPy?\n",
        "\n",
        "**Multi-dimensional arrays:**\n",
        "\n",
        "  At its core, NumPy provides support for large, multi-dimensional arrays and matrices. These arrays, called ndarrays, are the foundation for numerical computations in Python.   \n",
        "\n",
        "\n",
        "\n",
        "**Mathematical functions:**\n",
        "\n",
        "  NumPy also offers a vast collection of high-level mathematical functions to operate on these arrays, including:\n",
        "\n",
        "  Linear algebra operations   \n",
        "\n",
        "  Fourier transforms   \n",
        "\n",
        "  Random number generation   \n",
        "\n",
        "  Statistical functions   \n",
        "\n",
        "\n",
        "   **Efficiency:**\n",
        "\n",
        "  NumPy is designed for efficiency. Its arrays are stored contiguously in memory, and its operations are implemented in optimized C code, making it much faster than standard Python lists for numerical tasks.   \n",
        "\n",
        "\n",
        "\n",
        "  Why is it widely used?\n",
        "\n",
        "**Performance:**\n",
        "\n",
        "  NumPy's speed is crucial for handling large datasets, which are common in scientific computing, data analysis, and machine learning.   \n",
        "\n",
        "\n",
        "**Foundation for other libraries:**\n",
        "\n",
        "  Many other popular Python libraries, such as Pandas, SciPy, and Scikit-learn, are built on top of NumPy. It serves as the underlying array structure for these libraries.   \n",
        "\n",
        "\n",
        "\n",
        "**Data analysis and scientific computing:**\n",
        "\n",
        "**NumPy is essential for tasks like:**\n",
        "\n",
        "  Data manipulation and analysis\n",
        "\n",
        "  Mathematical modeling\n",
        "\n",
        "  Image processing\n",
        "\n",
        "  Machine learning"
      ],
      "metadata": {
        "id": "4N3n0j3vqLHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. How does broadcasting work in NumPy?\n",
        "\n",
        "     -> ->2answer-> NumPy's broadcasting is a powerful mechanism that allows NumPy to perform arithmetic operations on arrays with different shapes. Essentially, it \"stretches\" or \"repeats\" smaller arrays to match the shape of larger arrays, enabling element-wise operations. Here's a breakdown of how it works:   \n",
        "\n",
        "**Core Concepts:**\n",
        "\n",
        "**Compatibility:**\n",
        "\n",
        "  Broadcasting works when the dimensions of the arrays are compatible.   \n",
        "\n",
        "  Two dimensions are compatible when:\n",
        "\n",
        "  They are equal, or\n",
        "\n",
        "  One of them is 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Stretching:**\n",
        "\n",
        "  When dimensions are compatible, NumPy effectively stretches the array with the smaller dimension to match the larger one.\n",
        "\n",
        "  This \"stretching\" doesn't actually create copies of the data in memory, making broadcasting very efficient.   \n",
        "\n",
        "\n",
        "\n",
        "**Broadcasting Rules:**\n",
        "\n",
        "**Dimension Matching:**\n",
        "\n",
        "  NumPy compares the shapes of arrays element-wise, starting from the trailing (rightmost) dimensions.\n",
        "\n",
        "\n",
        "**Compatibility Check:**\n",
        "\n",
        "  If the dimensions are equal or one of them is 1, the dimensions are compatible.   \n",
        "\n",
        "\n",
        "\n",
        "**Broadcasting:**\n",
        "\n",
        "  If a dimension is 1, NumPy will \"broadcast\" that dimension by repeating the array along that dimension to match the size of the other array.\n",
        "\n",
        "\n",
        "**Rank Adjustment:**\n",
        "\n",
        "  If the arrays have a different number of dimensions, NumPy will prepend 1s to the shape of the smaller array until both arrays have the same number of dimensions."
      ],
      "metadata": {
        "id": "zpecvDdIrglt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What is a Pandas DataFrame?\n",
        "\n",
        "  -> ->3answer-> A Pandas DataFrame is a core data structure provided by the Pandas library in Python. It's designed for handling and manipulating tabular data, making it incredibly useful for data analysis and manipulation. Here's a breakdown:   \n",
        "\n",
        "**Key Characteristics:**\n",
        "\n",
        "**Two-Dimensional:**\n",
        "\n",
        "  A DataFrame is a 2D labeled data structure, meaning it organizes data into rows and columns, much like a spreadsheet or a SQL table.   \n",
        "\n",
        "\n",
        "\n",
        "**Labeled Axes:**\n",
        "\n",
        "  Both rows and columns have labels, known as indices. This allows for easy and intuitive access to data.   \n",
        "\n",
        "\n",
        "**Heterogeneous Data:**\n",
        "\n",
        "  Columns can contain different data types (e.g., integers, floats, strings, booleans), making it highly flexible.   \n",
        "\n",
        "\n",
        "\n",
        "**Size-Mutable:**\n",
        "\n",
        "  You can easily add or remove columns and rows.   \n",
        "\n",
        "\n",
        "\n",
        "**In simpler terms:**\n",
        "\n",
        "  Think of a DataFrame as a table in a database or a spreadsheet in Excel. It's a way to organize and work with data in a structured, row-and-column format.\n",
        "\n",
        "**Why it's important:**\n",
        "\n",
        "**Data Manipulation:**\n",
        "\n",
        "  Pandas DataFrames provide powerful tools for filtering, sorting, grouping, and transforming data.   \n",
        "\n",
        "\n",
        "\n",
        "**Data Analysis:**\n",
        "\n",
        "  They facilitate statistical analysis, data cleaning, and exploration.\n",
        "\n",
        "\n",
        "**Integration:**\n",
        "\n",
        "  DataFrames integrate seamlessly with other Python libraries like NumPy and Scikit-learn, making them a fundamental part of the Python data science ecosystem.   \n",
        "\n",
        "\n",
        "\n",
        "  In essence, the Pandas DataFrame is a versatile and efficient tool for working with structured data in Python."
      ],
      "metadata": {
        "id": "-FnaYZtqtDE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Explain the use of the groupby() method in Pandas.\n",
        "\n",
        "  -> ->4answer-> The groupby() method in Pandas is a very powerful tool for data analysis. It allows you to split your DataFrame into groups based on one or more columns, and then perform operations on those groups. Here's a breakdown of its use:\n",
        "\n",
        "**Core Functionality:**\n",
        "\n",
        "**Split-Apply-Combine:**\n",
        "   The groupby() method follows the \"split-apply-combine\" strategy:\n",
        "\n",
        "**Split:** The DataFrame is split into groups based on the values in\n",
        "  the specified column(s).\n",
        "\n",
        "**Apply:** A function is applied to each of the resulting groups\n",
        "  independently.\n",
        "\n",
        "**Combine:** The results of the function applications are combined into\n",
        "  a new DataFrame.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Aggregation:**\n",
        "\n",
        "  A common use of groupby() is to aggregate data within each group. This involves calculating summary statistics like:\n",
        "  sum(): Calculate the sum of values.\n",
        "  mean(): Calculate the average of values.\n",
        "  count(): Count the number of values.\n",
        "  min(): Find the minimum value.\n",
        "  max(): Find the maximum value.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Transformation:**\n",
        "\n",
        "  groupby() can also be used to transform data within each group. This involves applying a function that modifies the values in each group, while maintaining the same shape as the original data.\n",
        "\n",
        "\n",
        "\n",
        "**Filtering:**\n",
        "\n",
        "  You can use groupby() to filter groups based on certain conditions, allowing you to focus on specific subsets of your data.\n",
        "\n",
        "\n",
        "\n",
        "**How it Works:**\n",
        "\n",
        "**Grouping:**\n",
        "\n",
        "  You specify the column(s) by which you want to group the DataFrame.\n",
        "\n",
        "\n",
        "\n",
        "**GroupBy Object:**\n",
        "\n",
        "  The groupby() method returns a GroupBy object, which is an intermediate object that represents the groups.\n",
        "\n",
        "\n",
        "**Applying Functions:**\n",
        "\n",
        "  You can then apply various functions to this GroupBy object, such as aggregation, transformation, or filtering functions.\n",
        "\n",
        "\n",
        "**Result:**\n",
        "\n",
        "  The results are combined into a new DataFrame or Series.\n",
        "\n",
        "\n",
        "**Practical Applications:**\n",
        "\n",
        "  Calculating sales totals by product category.\n",
        "\n",
        "  Finding the average test scores for each class.\n",
        "\n",
        "  Analyzing customer behavior by region.\n",
        "\n",
        "  Generating summary reports.\n",
        "\n",
        "  In essence, groupby() provides a flexible and efficient way to analyze and summarize data based on different categories within your DataFrame."
      ],
      "metadata": {
        "id": "Ns9HsIdBuhyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Why is Seaborn preferred for statistical visualizations?\n",
        "\n",
        "  -> ->5answer-> Seaborn is a popular Python data visualization library, and it's particularly favored for statistical visualizations due to several key strengths:   \n",
        "\n",
        "**Statistical Focus:**\n",
        "\n",
        "  Seaborn is built specifically for statistical data visualization. It goes beyond simply plotting data points; it aims to reveal patterns and relationships within the data.   \n",
        "\n",
        "  It provides tools for visualizing distributions, relationships between variables, and statistical estimations.   \n",
        "\n",
        "**High-Level Interface:**\n",
        "\n",
        "  Seaborn offers a high-level interface that simplifies the creation of complex statistical plots. This means you can generate sophisticated visualizations with relatively few lines of code.   \n",
        "\n",
        "  It abstracts away many of the complexities of Matplotlib, which is the underlying plotting library.\n",
        "\n",
        "**Integration with Pandas:**\n",
        "\n",
        "  Seaborn integrates seamlessly with Pandas DataFrames, which are widely used for data manipulation in Python.\n",
        "  This makes it easy to visualize data directly from your\n",
        "  Pandas data structures.   \n",
        "\n",
        "**Attractive and Informative Visualizations:**\n",
        "\n",
        "  Seaborn provides aesthetically pleasing default styles and color palettes, making it easy to create visually appealing plots.   \n",
        "\n",
        "  Its visualizations are not only attractive but also informative, helping you to gain insights from your data.   \n",
        "\n",
        "**Specialized Plot Types:**\n",
        "\n",
        "  Seaborn offers a variety of specialized plot types that are specifically designed for statistical analysis, including:\n",
        "\n",
        "  Distribution plots (histograms, KDE plots)   \n",
        "\n",
        "  Categorical plots (box plots, violin plots)   \n",
        "\n",
        "  Relational plots (scatter plots, line plots)   \n",
        "\n",
        "  Regression plots\n",
        "\n",
        "  Matrix plots (heatmaps)"
      ],
      "metadata": {
        "id": "MIBGXWcowZt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What are the differences between NumPy arrays and Python lists?\n",
        "\n",
        "   -> ->6answer-> Understanding the key differences between Python lists and NumPy arrays is crucial for efficient data manipulation and numerical computation. Here's a breakdown of their main distinctions:\n",
        "\n",
        "**Data Type:**\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Lists are highly flexible and can contain elements of various data types (integers, floats, strings, etc.) within the same list. This heterogeneity makes them versatile for general-purpose programming.   \n",
        "\n",
        "\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy arrays are homogeneous, meaning all elements within an array must be of the same data type. This uniformity is essential for efficient numerical operations.   \n",
        "\n",
        "\n",
        "\n",
        "**Performance:**\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Lists are generally slower for numerical computations, especially with large datasets. This is due to their dynamic nature and the overhead of handling different data types.\n",
        "\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy arrays are significantly faster for numerical operations. They are implemented in C, which allows for optimized computations and efficient memory management.\n",
        "\n",
        "\n",
        "\n",
        "**Memory Usage:**\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Lists tend to consume more memory due to the overhead of storing data type information for each element.\n",
        "\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy arrays are more memory-efficient because they store elements of the same data type contiguously in memory.   \n",
        "\n",
        "\n",
        "\n",
        "**Functionality:**\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Lists are designed for general-purpose data storage and manipulation. They provide methods for appending, inserting, removing, and sorting elements.   \n",
        "\n",
        "\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy arrays are optimized for numerical computations. They offer a wide range of mathematical functions, linear algebra operations, and array manipulation tools.   \n",
        "\n",
        "\n",
        "\n",
        "**Element-wise Operations:**\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Performing element-wise operations on lists typically requires explicit loops, which can be slow.\n",
        "\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy arrays allow for efficient element-wise operations using vectorized operations, which are much faster than loops."
      ],
      "metadata": {
        "id": "lsns8-UyoBCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 What is a heatmap, and when should it be used?\n",
        "\n",
        "  ->7answer-> A heatmap is a graphical representation of data where values are depicted by color. Essentially, it's a way to visualize data matrices, using color variations to show the magnitude of values. This makes it easy to quickly identify patterns and understand complex data.   \n",
        "\n",
        "  Here's a breakdown:\n",
        "\n",
        "**What a Heatmap Does:**\n",
        "\n",
        "**Visualizes Data Matrices:**\n",
        "\n",
        "  Heatmaps are particularly useful for displaying two-dimensional data, like tables or matrices.   \n",
        "\n",
        "**Uses Color Gradients:**\n",
        "\n",
        "  Different colors or color intensities represent different value ranges. This allows you to quickly see \"hot\" (high-value) and \"cold\" (low-value) areas.   \n",
        "\n",
        "\n",
        "**Highlights Patterns:**\n",
        "\n",
        "  Heatmaps make it easy to spot trends, clusters, and outliers in your data.   \n",
        "\n",
        "**When to Use a Heatmap:**\n",
        "\n",
        "  Heatmaps are valuable in various scenarios, including:\n",
        "\n",
        "**Correlation Analysis:**\n",
        "\n",
        "  To visualize the correlation between variables in a dataset.   \n",
        "\n",
        "\n",
        "**Website Analytics:**\n",
        "\n",
        "  To understand user behavior on websites, showing where users click, scroll, and hover.   \n",
        "\n",
        "**Genomics:**\n",
        "\n",
        "  To represent gene expression levels.   \n",
        "\n",
        "**Financial Data:**\n",
        "\n",
        "  To display stock market data or other financial metrics.   \n",
        "\n",
        "\n",
        "**Geographical Data:**\n",
        "\n",
        "  To show population density, crime rates, or other spatial data.   \n",
        "\n",
        "**Customer Behavior:**\n",
        "\n",
        "  To understand customer interaction with products, or services.   \n",
        "\n",
        "  Any situation where you want to show the intensity of data, over a 2 dimensional plane."
      ],
      "metadata": {
        "id": "FKypVfjrpnsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What does the term “vectorized operation” mean in NumPy?\n",
        "\n",
        "     -> ->8answer-> In NumPy, \"vectorized operation\" refers to the ability to perform operations on entire arrays at once, without the need for explicit Python loops. This is a fundamental concept that contributes significantly to NumPy's efficiency. Here's a more detailed explanation:   \n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "**Eliminating Python Loops:**\n",
        "\n",
        "  Traditional Python loops, like for loops, can be slow, especially when dealing with large datasets. Vectorized operations bypass these loops by performing operations on all elements of an array simultaneously.   \n",
        "\n",
        "\n",
        "\n",
        "**Underlying C Implementation:**\n",
        "\n",
        "  NumPy's vectorized operations are implemented in optimized C code. This allows for much faster execution compared to equivalent Python loops.   \n",
        "\n",
        "\n",
        "**Element-wise Operations:**\n",
        "\n",
        "  Vectorization enables efficient element-wise operations, where the same operation is applied to corresponding elements of arrays. For example, adding two NumPy arrays together results in the element-wise sum of their elements.   \n",
        "\n",
        "\n",
        "\n",
        "**Performance Benefits:**\n",
        "\n",
        "  Vectorized operations significantly improve performance, especially for numerical computations involving large datasets. This is a primary reason why NumPy is so widely used in scientific computing and data analysis.   \n",
        "\n",
        "\n",
        "\n",
        "**In simpler terms:**\n",
        "\n",
        "  Instead of processing each element of an array one by one, a vectorized operation processes all elements at the same time. This is like having a machine that can perform the same task on many items simultaneously, rather than having to do each one individually.\n",
        "\n",
        "**Why it's important:**\n",
        "\n",
        "  Vectorization is crucial for writing efficient NumPy code. It allows you to leverage the speed of NumPy's underlying C implementation, resulting in faster and more concise code.   \n",
        "\n",
        "  Essentially, \"vectorized operation\" means performing operations on entire arrays at once, which leads to significant performance improvements."
      ],
      "metadata": {
        "id": "wJLjrN6jrVsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. How does Matplotlib differ from Plotly?\n",
        "\n",
        "  ->9answer-> Matplotlib and Plotly are both Python libraries used for data visualization, but they differ significantly in their approach and capabilities. Here's a breakdown of their key differences:   \n",
        "\n",
        "**Matplotlib:**\n",
        "\n",
        "**Static Visualizations:**\n",
        "\n",
        "  Matplotlib primarily creates static, raster-based or vector-based images. These are excellent for print media, reports, and situations where interactivity is not required.   \n",
        "\n",
        "\n",
        "\n",
        "**High Customization:**\n",
        "\n",
        "  Matplotlib provides a very high degree of control over every element of a plot. This flexibility is powerful but can also lead to more complex code.   \n",
        "\n",
        "\n",
        "**Foundation Library:**\n",
        "\n",
        "  It's considered the foundational plotting library in Python, and many other libraries (like Seaborn) are built on top of it.   \n",
        "\n",
        "\n",
        "\n",
        "**Focus:**\n",
        "\n",
        "  Emphasis on creating publication-quality, static graphs.\n",
        "\n",
        "\n",
        "\n",
        "**Plotly:**\n",
        "\n",
        "**Interactive Visualizations:**\n",
        "\n",
        "  Plotly specializes in creating interactive, web-based visualizations. These plots allow users to zoom, pan, hover for data details, and perform other interactive actions.   \n",
        "\n",
        "\n",
        "\n",
        "**Web-Based:**\n",
        "\n",
        "  Plotly generates HTML-based plots, making them ideal for web applications, dashboards, and online sharing.   \n",
        "\n",
        "\n",
        "**Ease of Use (Plotly Express):**\n",
        "\n",
        "  Plotly Express, a high-level interface, simplifies the creation of complex interactive plots with minimal code.   \n",
        "\n",
        "\n",
        "\n",
        "**Focus:**\n",
        "\n",
        "  Emphasis on creating dynamic, interactive, and shareable visualizations."
      ],
      "metadata": {
        "id": "qGLYoS6Ls3Vz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the significance of hierarchical indexing in Pandas?\n",
        "\n",
        "   ->10answer-> Hierarchical indexing, also known as MultiIndexing, is a very important feature in Pandas that allows you to have multiple levels of indexes on an axis. This provides a way to work with higher-dimensional data in a lower-dimensional format, which is incredibly useful for data analysis. Here's a breakdown of its significance:   \n",
        "\n",
        "**Key Significance:**\n",
        "\n",
        "**Handling Higher-Dimensional Data:**\n",
        "\n",
        "  It enables you to represent and manipulate data with more than two dimensions (rows and columns) in a Pandas DataFrame or Series. This is particularly valuable when dealing with complex datasets that have multiple levels of categorization.   \n",
        "\n",
        "\n",
        "\n",
        "**Enhanced Data Organization:**\n",
        "\n",
        "  Hierarchical indexing provides a structured way to organize data, making it easier to understand and navigate. It allows you to group related data points together, which can improve data clarity.   \n",
        "\n",
        "\n",
        "**Efficient Data Slicing and Selection:**\n",
        "\n",
        "  With multiple index levels, you can perform more precise and efficient data slicing and selection. You can select subsets of data based on specific combinations of index values.   \n",
        "\n",
        "\n",
        "\n",
        "**Simplified Data Aggregation and Grouping:**\n",
        "\n",
        "  Hierarchical indexing works seamlessly with the groupby() method, allowing you to perform complex aggregations and group-based operations with ease. You can group data at different levels of the index and calculate summary statistics for each group.   \n",
        "\n",
        "\n",
        "**Reshaping Data:**\n",
        "\n",
        "  It facilitates data reshaping operations, such as stacking and unstacking, which can be used to transform data between different formats. This is helpful for preparing data for analysis or visualization."
      ],
      "metadata": {
        "id": "8BeVORkluDFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What is the role of Seaborn’s pairplot() function?\n",
        "\n",
        "  ->11answer-> Seaborn's pairplot() function is a powerful tool for exploratory data analysis (EDA). Its primary role is to visualize pairwise relationships between variables within a dataset. Here's a breakdown of its significance:\n",
        "\n",
        "**Key Functions:**\n",
        "\n",
        "**Visualizing Pairwise Relationships:**\n",
        "\n",
        "  pairplot() creates a matrix of scatter plots, where each scatter plot shows the relationship between two variables. This allows you to quickly see how different variables relate to each other.\n",
        "\n",
        "\n",
        "**Showing Distributions:**\n",
        "\n",
        "  Along the diagonal of the matrix, pairplot() displays the univariate distribution of each variable. This is typically shown as a histogram or a kernel density estimate (KDE), providing insights into the shape and spread of each variable's data.\n",
        "\n",
        "\n",
        "**Identifying Correlations:**\n",
        "\n",
        "  By examining the scatter plots, you can identify potential correlations between variables. This helps you understand which variables tend to increase or decrease together.\n",
        "\n",
        "\n",
        "**Detecting Patterns and Outliers:**\n",
        "\n",
        "  pairplot() can reveal patterns, clusters, and outliers in your data. This can help you identify anomalies or interesting trends that warrant further investigation.\n",
        "\n",
        "\n",
        "**Facilitating Exploratory Data Analysis (EDA):**\n",
        "\n",
        "  It provides a concise and comprehensive overview of the relationships between multiple variables, making it an essential tool for EDA."
      ],
      "metadata": {
        "id": "hctvx8ErvJto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is the purpose of the describe() function in Pandas?\n",
        "\n",
        "   ->12answer-> The describe() function in Pandas serves as a very useful tool for quickly obtaining descriptive statistics about your data. Here's a breakdown of its purpose:\n",
        "\n",
        "**Core Purpose:**\n",
        "\n",
        "**Statistical Summary:**\n",
        "\n",
        "  The primary purpose of describe() is to generate a summary of descriptive statistics for a Pandas DataFrame or Series. This provides a quick overview of the central tendency, dispersion, and shape of the data's distribution.\n",
        "\n",
        "\n",
        "**Exploratory Data Analysis (EDA):**\n",
        "\n",
        "  It's a crucial function for initial data exploration, allowing you to quickly understand the characteristics of your dataset.\n",
        "\n",
        "\n",
        "\n",
        "**What it Provides:**\n",
        "\n",
        "**For Numerical Data:**\n",
        "\n",
        "**count:** The number of non-null values.\n",
        "\n",
        "**mean:** The average value.\n",
        "\n",
        "**std:** The standard deviation, indicating the spread of the data.\n",
        "\n",
        "**min:** The minimum value.\n",
        "25%, 50%, 75%: The quartiles, representing the 25th, 50th (median), and 75th percentiles.\n",
        "\n",
        "**max:** The maximum value.\n",
        "\n",
        "\n",
        "**For Categorical Data (Object Types):**\n",
        "\n",
        "**count:** The number of non-null values.\n",
        "\n",
        "**unique:** The number of unique values.\n",
        "\n",
        "**top:** The most frequent value (mode).\n",
        "\n",
        "**freq:** The frequency of the most frequent value.\n",
        "\n",
        "\n",
        "\n",
        "**Key Use Cases:**\n",
        "\n",
        "**Initial Data Inspection:**\n",
        "\n",
        "  To get a quick understanding of the range, distribution, and central tendency of your data.\n",
        "\n",
        "\n",
        "**Identifying Outliers:**\n",
        "\n",
        "  By comparing the minimum and maximum values with the quartiles, you can identify potential outliers.\n",
        "\n",
        "\n",
        "**Understanding Data Distribution:**\n",
        "\n",
        "  The mean, standard deviation, and quartiles provide insights into the shape and spread of the data.\n",
        "\n",
        "\n",
        "\n",
        "**Data Cleaning:**\n",
        "\n",
        "  It helps in finding potential errors in your data."
      ],
      "metadata": {
        "id": "muL2bUAaxP7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Why is handling missing data important in Pandas?\n",
        "\n",
        "     ->13answer-> Handling missing data is crucial in Pandas because it directly impacts the accuracy and reliability of your data analysis. Here's why it's so important:   \n",
        "\n",
        "**Impact on Analysis:**\n",
        "\n",
        "**Biased Results:**\n",
        "\n",
        "  Missing data can introduce bias into your analysis. If missing values are not handled properly, they can skew your results and lead to inaccurate conclusions.   \n",
        "\n",
        "\n",
        "\n",
        "**Reduced Statistical Power:**\n",
        "\n",
        "  Missing data reduces the sample size, which can decrease the statistical power of your analysis. This means you may be less likely to detect real effects or relationships in your data.   \n",
        "\n",
        "\n",
        "**Inaccurate Models:**\n",
        "\n",
        "  Machine learning models often struggle with missing data. If you train a model on data with missing values, it may produce inaccurate predictions.   \n",
        "\n",
        "\n",
        "\n",
        "**Data Integrity:**\n",
        "\n",
        "**Maintaining Data Quality:**\n",
        "\n",
        "  Handling missing data is essential for maintaining the quality and integrity of your dataset. It ensures that your data is accurate and reliable.\n",
        "\n",
        "\n",
        "**Preventing Errors:**\n",
        "\n",
        "  Missing values can cause errors in calculations and data manipulations. Properly handling them prevents these errors.   \n",
        "\n",
        "\n",
        "\n",
        "**Practical Considerations:**\n",
        "\n",
        "**Real-World Data:**\n",
        "\n",
        "  Missing data is common in real-world datasets. Data may be missing due to errors in data collection, incomplete surveys, or other factors.   \n",
        "\n",
        "\n",
        "\n",
        "**Data Compatibility:**\n",
        "\n",
        "  Many analytical tools and libraries require complete datasets. Handling missing data ensures that your data is compatible with these tools.\n",
        "\n",
        "\n",
        "**Visualization Issues:**\n",
        "\n",
        "  Missing data can cause issues with visualizations, such as broken plots or misleading representations of data.   \n",
        "\n",
        "\n",
        "\n",
        "**Pandas Tools for Handling Missing Data:**\n",
        "\n",
        "  **Pandas provides several tools for handling missing data,\n",
        "  including:**\n",
        "\n",
        "**isnull() and notnull():** To detect missing values.\n",
        "\n",
        "**dropna():** To remove rows or columns with missing values.\n",
        "\n",
        "**fillna():** To fill missing values with specific values or using\n",
        " methods like interpolation."
      ],
      "metadata": {
        "id": "PuUO3ydz0VFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What are the benefits of using Plotly for data visualization?\n",
        "\n",
        "   ->14answer-> Plotly offers several compelling benefits for data visualization, particularly when compared to static plotting libraries like Matplotlib. Here's a breakdown of its key advantages:\n",
        "\n",
        "**Interactivity:**\n",
        "\n",
        "**Dynamic Exploration:**\n",
        "\n",
        "  Plotly visualizations are inherently interactive. Users can zoom, pan, hover over data points for detailed information, and perform other interactive actions. This allows for deeper exploration and understanding of the data.   \n",
        "\n",
        "\n",
        "\n",
        "**Enhanced User Engagement:**\n",
        "\n",
        "  Interactive plots are more engaging and can make data presentations more dynamic and informative.   \n",
        "\n",
        "\n",
        "\n",
        "**Web-Based Visualizations:**\n",
        "\n",
        "**Easy Sharing:**\n",
        "\n",
        "  Plotly generates HTML-based plots, making them easily shareable online. You can embed them in web applications, dashboards, or share them as standalone HTML files.   \n",
        "\n",
        "\n",
        "\n",
        "**Cross-Platform Compatibility:**\n",
        "\n",
        "  Because they're web-based, Plotly visualizations can be viewed in any modern web browser, regardless of the user's operating system.\n",
        "\n",
        "\n",
        "**Plotly Express (Ease of Use):**   \n",
        "\n",
        "**Simplified Plot Creation:**\n",
        "\n",
        "  Plotly Express provides a high-level interface that simplifies the creation of complex interactive plots with minimal code. This makes it accessible to users with varying levels of programming expertise.   \n",
        "\n",
        "\n",
        "**Rapid Prototyping:**\n",
        "\n",
        "  You can quickly create and iterate on visualizations, which is valuable for exploratory data analysis.\n",
        "\n",
        "\n",
        "\n",
        "**Wide Range of Plot Types:**\n",
        "\n",
        "**Versatile Visualization Options:**\n",
        "\n",
        "  Plotly supports a wide range of plot types, including scatter plots, line plots, bar charts, histograms, 3D plots, geographical maps, and more.   \n",
        "\n",
        "\n",
        "\n",
        "**Specialized Visualizations:**\n",
        "\n",
        "  It offers specialized visualizations for scientific, financial, and other domains.   \n",
        "\n",
        "\n",
        "\n",
        "**Dash Integration:**\n",
        "\n",
        "**Interactive Dashboards:**\n",
        "\n",
        "  Plotly integrates seamlessly with Dash, a Python framework for building interactive web applications and dashboards. This allows you to create powerful and customizable data dashboards.   \n",
        "\n",
        "\n",
        "\n",
        "**Application Development:**\n",
        "\n",
        "  This allows for the creation of full web applications that display and manipulate data.\n",
        "\n",
        "\n",
        "\n",
        "**Aesthetic Appeal:**\n",
        "\n",
        "**Modern and Professional Look:**\n",
        "\n",
        "  Plotly visualizations have a modern and professional aesthetic, making them visually appealing and suitable for presentations and reports."
      ],
      "metadata": {
        "id": "rZBr-hQJ2lg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How does NumPy handle multidimensional arrays?\n",
        "\n",
        "   ->15answer-> NumPy's ability to efficiently handle multidimensional arrays is a cornerstone of its functionality. Here's how it works:\n",
        "\n",
        "**The ndarray Object:**\n",
        "\n",
        "  At the heart of NumPy is the ndarray (n-dimensional array) object. This is a powerful data structure that stores elements of the same data type in a contiguous block of memory.   \n",
        "\n",
        "  This contiguity is a key factor in NumPy's performance, as it allows for efficient access and manipulation of data.   \n",
        "\n",
        "**Shape and Strides:**\n",
        "\n",
        "**Shape:**\n",
        "\n",
        "  A NumPy array has a \"shape,\" which is a tuple of integers that specifies the size of each dimension. For example, a 2D array (a matrix) might have a shape of (3, 4), meaning it has 3 rows and 4 columns.   \n",
        "\n",
        "\n",
        "\n",
        "**Strides:**\n",
        "\n",
        "  \"Strides\" determine how many bytes you need to jump in memory to move to the next element along each dimension. This allows NumPy to efficiently navigate the array's memory layout.   \n",
        "\n",
        "\n",
        "\n",
        "**Memory Layout:**\n",
        "\n",
        "  NumPy stores array data in a contiguous block of memory. This contrasts with Python lists, which can store elements scattered throughout memory.   \n",
        "\n",
        "**This contiguous memory layout enables:**\n",
        "\n",
        "**Efficient access:** NumPy can quickly access elements by calculating\n",
        "  memory offsets.\n",
        "\n",
        "**Vectorized operations:** NumPy can perform operations on entire\n",
        "  arrays without explicit loops, leveraging the contiguity for speed.   \n",
        "\n",
        "\n",
        "\n",
        "**Indexing and Slicing:**\n",
        "\n",
        "  NumPy provides powerful indexing and slicing capabilities that allow you to access and manipulate subsets of multidimensional arrays.   \n",
        "\n",
        "  You can use integer indices, slices, and boolean arrays to select specific elements or ranges of elements.   \n",
        "\n",
        "**Operations:**\n",
        "\n",
        "  NumPy supports a wide range of operations on multidimensional arrays, including:\n",
        "\n",
        "**Element-wise operations:** Operations are performed on corresponding\n",
        "  elements of arrays.   \n",
        "\n",
        "**Linear algebra operations:** Matrix multiplication, inversion, and\n",
        "  other linear algebra operations.   \n",
        "\n",
        "**Aggregation operations:** Sum, mean, and other aggregation operations\n",
        "  across dimensions.   \n",
        "\n",
        "**Broadcasting:** This allows for operations on arrays with different\n",
        "  shapes."
      ],
      "metadata": {
        "id": "w9ibtY_h4rrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the role of Bokeh in data visualization?\n",
        "\n",
        "  ->16answer-> Bokeh plays a significant role in the realm of data visualization, particularly when interactivity and web-based presentations are crucial. Here's a breakdown of its key roles:\n",
        "\n",
        "**Core Functionality:**\n",
        "\n",
        "**Interactive Visualizations:**\n",
        "\n",
        "  Bokeh's primary strength lies in creating interactive plots and visualizations that can be displayed in modern web browsers. This allows users to explore data dynamically through zooming, panning, and hovering over data points.   \n",
        "\n",
        "\n",
        "\n",
        "**Web-Based Output:**\n",
        "\n",
        "  It generates visualizations in HTML, CSS, and JavaScript, making them readily embeddable in web applications and dashboards. This facilitates easy sharing and distribution of interactive data insights.   \n",
        "\n",
        "\n",
        "**Large Datasets:**\n",
        "\n",
        "  Bokeh is designed to handle large datasets efficiently, enabling smooth and responsive interactions even with substantial amounts of data.\n",
        "\n",
        "\n",
        "**Versatility:**\n",
        "\n",
        "  It supports a wide range of visualization types, including line plots, scatter plots, bar charts, and more complex visualizations.   \n",
        "\n",
        "\n",
        "\n",
        "**Key Roles and Benefits:**\n",
        "\n",
        "**Enhanced Data Exploration:**\n",
        "\n",
        "  The interactive nature of Bokeh allows users to delve deeper into data, uncovering patterns and insights that might be missed with static visualizations.   \n",
        "\n",
        "\n",
        "**Interactive Dashboards and Applications:**\n",
        "\n",
        "  Bokeh is well-suited for building interactive dashboards and web-based data applications, providing a dynamic and engaging user experience.   \n",
        "\n",
        "\n",
        "\n",
        "**Real-Time Data Visualization:**\n",
        "\n",
        "  It can handle streaming data, making it useful for visualizing real-time data feeds and monitoring applications.   \n",
        "\n",
        "\n",
        "\n",
        "**Accessibility:**\n",
        "\n",
        "  Because it generates web-based output, Bokeh visualizations can be accessed from any device with a web browser, enhancing accessibility and sharing.   \n",
        "\n",
        "\n",
        "\n",
        "  In essence, Bokeh empowers users to create dynamic and engaging data visualizations that facilitate deeper data exploration and communication."
      ],
      "metadata": {
        "id": "v7XS-0-P6dSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Explain the difference between apply() and map() in Pandas?\n",
        "\n",
        "   ->17answer-> When working with Pandas, apply() and map() are both used to apply functions to data, but they operate at different levels and have distinct use cases. Here's a breakdown of their differences:\n",
        "\n",
        "**Scope of Application:**\n",
        "\n",
        "**map():**\n",
        "\n",
        "  This method is specifically designed to work on Pandas Series objects. It performs element-wise operations, meaning it applies a function to each individual element of the Series.\n",
        "\n",
        "\n",
        "**apply():**\n",
        "\n",
        "  This method is more versatile and can be used on both Pandas Series and DataFrames.\n",
        "\n",
        "  When used on a Series, it can perform element-wise operations, similar to map(), but it's also capable of handling more complex functions.\n",
        "\n",
        "  When used on a DataFrame, it can apply a function along an axis (either rows or columns).\n",
        "\n",
        "\n",
        "\n",
        "**Function Application:**\n",
        "\n",
        "**map():**\n",
        "\n",
        "  Primarily used for mapping values from one set to another. It can accept a dictionary, a Series, or a callable function as input.\n",
        "\n",
        "  It's optimized for element-wise substitutions and transformations.\n",
        "\n",
        "\n",
        "**apply():**\n",
        "\n",
        "  More general-purpose. It accepts a callable function as input and can handle more complex operations, including those that involve multiple elements or require aggregation.\n",
        "\n",
        "  It can be used for element-wise transformations, but it's particularly useful for applying functions that operate on entire rows or columns.\n",
        "\n",
        "\n",
        "\n",
        "**Use Cases:**\n",
        "\n",
        "**map():**\n",
        "\n",
        "  Ideal for simple element-wise transformations, such as replacing values or formatting strings.\n",
        "\n",
        "  Especially efficient when using a dictionary to map values.\n",
        "\n",
        "\n",
        "\n",
        "**apply():**\n",
        "\n",
        "  Suitable for more complex operations, such as applying custom functions that require access to multiple columns or rows.\n",
        "\n",
        "  Useful for aggregating data along axes or performing transformations that cannot be vectorized."
      ],
      "metadata": {
        "id": "BIuO3imaAmA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are some advanced features of NumPy?\n",
        "\n",
        "   ->18answer-> NumPy, while known for its fundamental array operations, also offers a range of advanced features that enhance its capabilities for complex numerical computations. Here are some of them:   \n",
        "\n",
        "**Advanced Indexing:**\n",
        "\n",
        "**Boolean Indexing:**\n",
        "\n",
        "  Allows you to select elements based on a boolean mask, enabling efficient filtering and conditional operations.   \n",
        "\n",
        "\n",
        "\n",
        "**Fancy Indexing:**\n",
        "\n",
        "  Allows you to select elements using arrays of indices, providing powerful and flexible ways to access subsets of data.   \n",
        "\n",
        "\n",
        "\n",
        "**Broadcasting Rules (Advanced):**\n",
        "\n",
        "  While basic broadcasting is common, understanding the finer points of how NumPy handles broadcasting in complex scenarios is crucial for efficient array manipulation. This includes understanding how NumPy handles arrays with varying numbers of dimensions and how it prepends 1s to smaller arrays.\n",
        "\n",
        "**Structured Arrays:**\n",
        "\n",
        "  Allow you to create arrays with heterogeneous data types, similar to records in a database or structs in C. This is useful for representing complex data structures.\n",
        "\n",
        "**Memory Mapping:**\n",
        "\n",
        "  Enables you to work with very large datasets that don't fit into memory by mapping arrays to files on disk. This allows you to access and manipulate data without loading it entirely into RAM.   \n",
        "\n",
        "**Universal Functions (ufuncs) - Advanced:**\n",
        "\n",
        "**Custom ufuncs:**\n",
        "\n",
        "  NumPy allows you to create your own ufuncs, which can be compiled to C for maximum performance.   \n",
        "\n",
        "\n",
        "**ufunc methods:**\n",
        "\n",
        "  ufuncs have methods like .reduce(), .accumulate(), and .outer() that can be utilized to perform very efficient complex operations.\n",
        "\n",
        "\n",
        "\n",
        "**Linear Algebra (linalg) Module:**\n",
        "\n",
        "**Provides a comprehensive set of linear algebra functions**, **including:**\n",
        "\n",
        "  Matrix decompositions (SVD, QR)   \n",
        "\n",
        "  Eigenvalue and eigenvector calculations   \n",
        "\n",
        "  Solving linear equations   \n",
        "\n",
        "  Matrix norms and determinants   \n",
        "\n",
        "\n",
        "\n",
        "**Fourier Transform (fft) Module:**\n",
        "\n",
        "  Offers functions for performing fast Fourier transforms (FFTs), which are essential for signal processing and other applications.\n",
        "\n",
        "**Random Number Generation (random) Module -\n",
        "Advanced:**\n",
        "\n",
        "**Provides a wide range of random number distributions and functions, including:**\n",
        "\n",
        "  Permutations and shuffling\n",
        "  Sampling from various probability distributions\n",
        "  Random number generators with different algorithms and properties\n",
        "\n",
        "\n",
        "\n",
        "**C-API and Cython Integration:**\n",
        "\n",
        "  NumPy's C-API allows you to integrate NumPy arrays with C and C++ code, enabling you to write highly optimized numerical algorithms.   \n",
        "\n",
        "  Cython also allows for the easy integration of C code with python, to access or manipulate numpy arrays.\n",
        "\n",
        "**Array Programming with np.einsum:**\n",
        "\n",
        "  np.einsum allows to compute sums of products in a very concise way. It provides a very powerful, albeit somewhat complex, way to express many common array operations.\n",
        "\n",
        "  These advanced features make NumPy a powerful tool for a wide range of numerical computing tasks, from basic data manipulation to complex scientific simulations."
      ],
      "metadata": {
        "id": "pho8cfzmCMoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How does Pandas simplify time series analysis?\n",
        "\n",
        "     ->19answer-> Pandas significantly simplifies time series analysis in Python through its specialized data structures and functionalities. Here's how:   \n",
        "\n",
        "**Specialized Data Structures:**\n",
        "\n",
        "**DatetimeIndex:**\n",
        "\n",
        "  Pandas provides the DatetimeIndex, a specialized index for time series data. It allows for efficient time-based indexing, slicing, and resampling.\n",
        "\n",
        "\n",
        "**Timestamp:**\n",
        "\n",
        "  The Timestamp object represents a single point in time, offering detailed information like year, month, day, hour, minute, and second.\n",
        "\n",
        "\n",
        "**Period:**\n",
        "\n",
        "  The Period object represents a time span, such as a day, month, or year.\n",
        "\n",
        "\n",
        "**Timedelta:**\n",
        "\n",
        "  The Timedelta object represents a duration, such as the difference between two timestamps.\n",
        "\n",
        "\n",
        "\n",
        "**Time-Based Indexing and Slicing:**\n",
        "\n",
        "  Pandas allows you to easily select data based on time ranges, such as \"all data from January 2023\" or \"data from the last week.\"   \n",
        "\n",
        "  You can use partial string indexing, like df['2023-01'], to select data within a specific month.\n",
        "\n",
        "**Resampling:**\n",
        "\n",
        "  The resample() method enables you to change the frequency of your time series data. You can upsample (increase frequency) or downsample (decrease frequency).   \n",
        "\n",
        "  Resampling allows you to aggregate data into different time intervals, such as daily to weekly or monthly.   \n",
        "\n",
        "**Time Zone Handling:**\n",
        "\n",
        "  Pandas provides robust support for time zones, allowing you to convert time series data between different time zones.   \n",
        "\n",
        "  This is crucial for handling data from multiple locations or dealing with daylight saving time.\n",
        "\n",
        "**Shifting and Lagging:**\n",
        "\n",
        "  The shift() method allows you to shift time series data forward or backward in time, which is useful for calculating lagged variables or analyzing trends.\n",
        "\n",
        "**Rolling Window Functions:**\n",
        "\n",
        "  Pandas provides rolling window functions, such as rolling(), which allow you to calculate moving averages, standard deviations, and other statistics over a rolling window of time.\n",
        "\n",
        "  These are extremely useful for smoothing noisy time series data, and identifying trends.\n",
        "\n",
        "**Period and Time Span Calculations:**\n",
        "\n",
        "  Pandas has features that allow for easy calculations involving time periods, and time spans. Such as finding the difference between two dates.   \n",
        "\n",
        "**Integration with Other Libraries:**\n",
        "\n",
        "  Pandas integrates seamlessly with other Python libraries, such as NumPy, Matplotlib, and Statsmodels, which are used for advanced time series analysis and modeling."
      ],
      "metadata": {
        "id": "AreNH_osEfM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is the role of a pivot table in Pandas?\n",
        "\n",
        "   ->20answer-> A pivot table in Pandas is a powerful tool for summarizing and reorganizing data, making it easier to analyze and understand complex relationships within a dataset. Here's a breakdown of its role:   \n",
        "\n",
        "**Core Functionality:**\n",
        "\n",
        "**Data Aggregation and Summarization:**\n",
        "\n",
        "  Pivot tables allow you to aggregate data based on one or more categorical variables. This involves calculating summary statistics, such as sums, averages, counts, or other aggregations, for different groups of data.   \n",
        "\n",
        "\n",
        "\n",
        "**Data Reshaping and Restructuring:**\n",
        "\n",
        "  They reshape data by transforming it from a \"long\" format (where data is stacked vertically) to a \"wide\" format (where data is spread horizontally). This makes it easier to compare and analyze data across different categories.\n",
        "\n",
        "\n",
        "**Cross-Tabulation:**\n",
        "\n",
        "  Pivot tables are used to create cross-tabulations, which display the relationship between two or more categorical variables. This allows you to see how different categories interact with each other.\n",
        "\n",
        "\n",
        "**Key Roles and Benefits:**\n",
        "\n",
        "**Simplified Data Analysis:**\n",
        "\n",
        "  Pivot tables simplify complex data analysis by providing a concise and organized view of the data.   \n",
        "\n",
        "\n",
        "**Identifying Patterns and Trends:**\n",
        "\n",
        "  They help identify patterns and trends in data by summarizing and reorganizing it in a meaningful way.   \n",
        "\n",
        "\n",
        "\n",
        "**Data Exploration:**\n",
        "\n",
        "  Pivot tables are valuable tools for exploratory data analysis (EDA), allowing you to quickly explore different aspects of your data.   \n",
        "\n",
        "\n",
        "**Report Generation:**\n",
        "\n",
        "  They can be used to generate summary reports that present key findings in a clear and concise manner.   \n",
        "\n",
        "\n",
        "\n",
        "**Enhanced Data Visualization:**\n",
        "\n",
        "  The output of a pivot table is a DataFrame, that can then be easily used to generate visualizations.\n",
        "\n",
        "\n",
        "**How it Works:**\n",
        "\n",
        "  You specify the variables you want to use as row indices, column indices, and values.\n",
        "\n",
        "  Pandas then groups the data based on the row and column indices and calculates the specified aggregation function for each group.\n",
        "\n",
        "  The result is a new DataFrame that represents the pivot table."
      ],
      "metadata": {
        "id": "3Id6jg2lG3fW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Why is NumPy’s array slicing faster than Python’s list slicing?\n",
        "\n",
        "   ->21answer-> NumPy's array slicing is significantly faster than Python's list slicing due to fundamental differences in how these data structures are stored and accessed in memory. Here's a breakdown of the reasons:\n",
        "\n",
        "**Contiguous Memory Allocation:**\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy arrays store their elements in a contiguous block of memory. This means that all elements are located next to each other in memory, allowing for efficient access.\n",
        "\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Python lists, on the other hand, store pointers to objects scattered throughout memory. This means that elements are not necessarily located next to each other, requiring the interpreter to follow pointers to access each element.\n",
        "\n",
        "\n",
        "\n",
        "**Optimized C Implementation:**\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy is implemented in C, which is a low-level language that allows for highly optimized memory management and operations. Slicing operations in NumPy are performed by directly manipulating memory addresses, which is very fast.\n",
        "\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Python lists are implemented in Python, which is a higher-level language. Slicing operations in Python lists involve creating new list objects and copying elements, which is a slower process.\n",
        "\n",
        "\n",
        "\n",
        "**View vs. Copy:**\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  In many cases, NumPy array slicing returns a \"view\" of the original array, rather than a copy. This means that the sliced array shares the same underlying data as the original array, avoiding the overhead of copying data. This is only possible because of the contiguous memory structure.\n",
        "\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Python list slicing always creates a new list object and copies the selected elements. This copy operation introduces significant overhead, especially for large lists.\n",
        "\n",
        "\n",
        "\n",
        "**Data Type Homogeneity:**\n",
        "\n",
        "**NumPy Arrays:**\n",
        "\n",
        "  NumPy arrays are homogeneous, meaning all elements have the same data type. This allows NumPy to perform memory calculations and access elements more efficiently.\n",
        "\n",
        "\n",
        "\n",
        "**Python Lists:**\n",
        "\n",
        "  Python lists can contain elements of different data types, which requires additional overhead for type checking and memory management."
      ],
      "metadata": {
        "id": "4fqefcNvIxY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. What are some common use cases for Seaborn?\n",
        "\n",
        "     ->22answer-> Seaborn is a powerful Python data visualization library, and it excels in creating insightful statistical graphics. Here are some common use cases:   \n",
        "\n",
        "**Exploring Relationships Between Variables:**\n",
        "\n",
        "**Scatter Plots (sns.scatterplot()):**\n",
        "\n",
        "  Visualizing the relationship between two numerical variables.   \n",
        "\n",
        "  Identifying correlations and patterns.   \n",
        "\n",
        "\n",
        "   \n",
        "**Pair Plots (sns.pairplot()):**\n",
        "\n",
        "  Exploring pairwise relationships between multiple variables in a dataset.   \n",
        "\n",
        "  Quickly identifying potential correlations and distributions.\n",
        "\n",
        "   \n",
        "**Relational Plots (sns.relplot()):**\n",
        "\n",
        "  Generalizing scatter plots and line plots to show relationships with semantic mappings (e.g., color, size, style).   \n",
        "\n",
        "\n",
        "   \n",
        "**Regression Plots (sns.regplot() and sns.lmplot()):**\n",
        "\n",
        "  Visualizing linear regression models and confidence intervals.   \n",
        "\n",
        "  Understanding the relationship between variables and how well a linear model fits the data.\n",
        "\n",
        "\n",
        "**Visualizing Distributions:**\n",
        "\n",
        "**Histograms (sns.histplot()):**\n",
        "\n",
        "  Showing the distribution of a single numerical variable.   \n",
        "\n",
        "  Understanding the frequency of different values.   \n",
        "\n",
        "\n",
        "   \n",
        "**Kernel Density Plots (sns.kdeplot()):**\n",
        "\n",
        "  Visualizing the probability density of a continuous variable.\n",
        "\n",
        "  Smoothing out histograms to reveal underlying distributions.\n",
        "\n",
        "   \n",
        "\n",
        "**Distribution Plots (sns.displot()):**\n",
        "\n",
        "  A figure level interface to histplot() and kdeplot() and other distribution plots.   \n",
        "\n",
        "   \n",
        "\n",
        "**Rug Plots (sns.rugplot()):**\n",
        "\n",
        "  Showing the location of individual data points along a single axis.\n",
        "\n",
        "  Useful for visualizing the distribution of sparse data.\n",
        "\n",
        "   \n",
        "\n",
        "**Visualizing Categorical Data:**\n",
        "\n",
        "**Box Plots (sns.boxplot()):**\n",
        "\n",
        "  Comparing the distribution of a numerical variable across different categories.   \n",
        "\n",
        "  Identifying outliers and understanding the spread of data.\n",
        "\n",
        "   \n",
        "**Violin Plots (sns.violinplot()):**\n",
        "\n",
        "  Combining box plots and kernel density plots to visualize the distribution of a numerical variable across categories.   \n",
        "\n",
        "  Providing a more detailed view of the distribution.\n",
        "\n",
        "   \n",
        "**Bar Plots (sns.barplot()):**\n",
        "\n",
        "  Comparing the mean or other aggregate values of a numerical variable across different categories.\n",
        "\n",
        "  Visualizing categorical data with error bars.   \n",
        "\n",
        "\n",
        "   \n",
        "**Count Plots (sns.countplot()):**\n",
        "\n",
        "  Showing the frequency of observations in each category.   \n",
        "\n",
        "  Visualizing the distribution of categorical variables.   \n",
        "\n",
        "   \n",
        "\n",
        "**Categorical Plots (sns.catplot()):**\n",
        "\n",
        "  A figure level interface to boxplot(), violinplot(), barplot(), and other categorical plots.\n",
        "\n",
        "   \n",
        "\n",
        "**Visualizing Matrices:**\n",
        "\n",
        "**Heatmaps (sns.heatmap()):**\n",
        "\n",
        "  Visualizing the correlation matrix between variables.   \n",
        "\n",
        "  Showing the intensity of data values in a matrix format.\n",
        "\n",
        "  Displaying confusion matrices.   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Enhancing Matplotlib Visualizations:**\n",
        "\n",
        "  Seaborn can be used to improve the aesthetics of Matplotlib plots by providing default styles and color palettes.   \n",
        "\n",
        "  It simplifies the creation of complex statistical plots that would be more difficult to create with Matplotlib alone."
      ],
      "metadata": {
        "id": "8LdAu24gKaZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Tool Kit Assignment Practicle Question"
      ],
      "metadata": {
        "id": "NXp5UOUtMmCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 How do you create a 2D NumPy array and calculate the sum of each row?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_row_sums(array_2d):\n",
        "  \"\"\"\n",
        "  Creates a 2D NumPy array and calculates the sum of each row.\n",
        "\n",
        "  Args:\n",
        "    array_2d: A 2D NumPy array.\n",
        "\n",
        "  Returns:\n",
        "    A 1D NumPy array containing the sum of each row.\n",
        "  \"\"\"\n",
        "  row_sums = np.sum(array_2d, axis=1)\n",
        "  return row_sums\n",
        "\n",
        "# Example usage:\n",
        "# Create a 2D NumPy array\n",
        "my_array = np.array([[1, 2, 3],\n",
        "                     [4, 5, 6],\n",
        "                     [7, 8, 9]])\n",
        "\n",
        "# Calculate the sum of each row\n",
        "row_sums = calculate_row_sums(my_array)\n",
        "\n",
        "# Print the results\n",
        "print(\"Original array:\")\n",
        "print(my_array)\n",
        "print(\"\\nRow sums:\")\n",
        "print(row_sums)\n",
        "\n",
        "#Example with a different sized array\n",
        "my_array2 = np.array([[10, 20],\n",
        "                     [30, 40],\n",
        "                     [50, 60],\n",
        "                     [70, 80]])\n",
        "\n",
        "row_sums2 = calculate_row_sums(my_array2)\n",
        "\n",
        "print(\"\\nOriginal array 2:\")\n",
        "print(my_array2)\n",
        "print(\"\\nRow sums 2:\")\n",
        "print(row_sums2)\n",
        "\n",
        "#Example with floats\n",
        "my_array3 = np.array([[1.5, 2.5, 3.5],\n",
        "                     [4.5, 5.5, 6.5]])\n",
        "\n",
        "row_sums3 = calculate_row_sums(my_array3)\n",
        "\n",
        "print(\"\\nOriginal array 3:\")\n",
        "print(my_array3)\n",
        "print(\"\\nRow sums 3:\")\n",
        "print(row_sums3)\n",
        "\n",
        "#Example with negative numbers\n",
        "my_array4 = np.array([[-1, 2, -3],\n",
        "                     [4, -5, 6]])\n",
        "\n",
        "row_sums4 = calculate_row_sums(my_array4)\n",
        "\n",
        "print(\"\\nOriginal array 4:\")\n",
        "print(my_array4)\n",
        "print(\"\\nRow sums 4:\")\n",
        "print(row_sums4)"
      ],
      "metadata": {
        "id": "cQgAFISgM788"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Write a Pandas script to find the mean of a specific column in a DataFrame.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_column_mean(dataframe, column_name):\n",
        "  \"\"\"\n",
        "  Calculates the mean of a specific column in a Pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    dataframe: The Pandas DataFrame.\n",
        "    column_name: The name of the column to calculate the mean of.\n",
        "\n",
        "  Returns:\n",
        "    The mean of the specified column, or None if the column doesn't exist.\n",
        "  \"\"\"\n",
        "  if column_name in dataframe.columns:\n",
        "    return dataframe[column_name].mean()\n",
        "  else:\n",
        "    print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "# Create a sample DataFrame\n",
        "data = {'col1': [1, 2, 3, 4, 5],\n",
        "        'col2': [10.0, 20.0, 30.0, 40.0, 50.0],\n",
        "        'col3': ['a', 'b', 'c', 'd', 'e']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the mean of 'col1'\n",
        "mean_col1 = calculate_column_mean(df, 'col1')\n",
        "if mean_col1 is not None:\n",
        "  print(f\"Mean of 'col1': {mean_col1}\")\n",
        "\n",
        "# Calculate the mean of 'col2'\n",
        "mean_col2 = calculate_column_mean(df, 'col2')\n",
        "if mean_col2 is not None:\n",
        "  print(f\"Mean of 'col2': {mean_col2}\")\n",
        "\n",
        "# Attempt to calculate the mean of a non-existent column\n",
        "mean_col4 = calculate_column_mean(df, 'col4')\n",
        "\n",
        "#Example with non numeric column\n",
        "mean_col3 = calculate_column_mean(df, 'col3')"
      ],
      "metadata": {
        "id": "ydVEcSo3_pum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Create a scatter plot using Matplotlib.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate some sample data\n",
        "np.random.seed(0)  # For reproducibility\n",
        "x = np.random.rand(50) * 10  # 50 random x values between 0 and 10\n",
        "y = 2 * x + np.random.randn(50) * 5  # 50 random y values with some noise\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(8, 6))  # Set the figure size (optional)\n",
        "plt.scatter(x, y, c='blue', marker='o', alpha=0.7, label='Data Points') #create scatter plot\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.title(\"Scatter Plot Example\")\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Add a grid (optional)\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "#Example with different colors and markers.\n",
        "x2 = np.random.rand(50) * 10\n",
        "y2 = 3 * x2 + np.random.randn(50) * 3\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(x,y, c = 'red', marker = '^', alpha = 0.5, label = \"Data Set 1\")\n",
        "plt.scatter(x2,y2, c = 'green', marker = 's', alpha = 0.5, label = \"Data Set 2\")\n",
        "plt.xlabel(\"X-axis\")\n",
        "plt.ylabel(\"Y-axis\")\n",
        "plt.title(\"Scatter Plot with multiple data sets\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hXlia1qZARKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame (you can replace this with your data)\n",
        "np.random.seed(0)\n",
        "data = {'A': np.random.rand(100),\n",
        "        'B': np.random.rand(100) * 2,\n",
        "        'C': np.random.rand(100) * 3,\n",
        "        'D': np.random.rand(100) * 4}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Visualize the correlation matrix with a heatmap\n",
        "plt.figure(figsize=(10, 8))  # Adjust figure size as needed\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "#Example with different correlation method\n",
        "correlation_matrix_pearson = df.corr(method='pearson') #default\n",
        "correlation_matrix_kendall = df.corr(method='kendall')\n",
        "correlation_matrix_spearman = df.corr(method='spearman')\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix_pearson, annot=True, cmap='viridis', linewidths=.5)\n",
        "plt.title('Pearson Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix_kendall, annot=True, cmap='plasma', linewidths=.5)\n",
        "plt.title('Kendall Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix_spearman, annot=True, cmap='magma', linewidths=.5)\n",
        "plt.title('Spearman Correlation Matrix Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UEQCWr8_A0ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Generate a bar plot using Plotly.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Sample data\n",
        "categories = ['Category A', 'Category B', 'Category C', 'Category D']\n",
        "values = [20, 35, 15, 45]\n",
        "\n",
        "# Create the bar plot\n",
        "fig = go.Figure(data=[go.Bar(x=categories, y=values)])\n",
        "\n",
        "# Customize the layout (optional)\n",
        "fig.update_layout(\n",
        "    title='Bar Plot Example',\n",
        "    xaxis_title='Categories',\n",
        "    yaxis_title='Values',\n",
        "    template='plotly_white' # Optional: set a template\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "# Example with different colors and labels\n",
        "categories2 = ['Group 1', 'Group 2', 'Group 3']\n",
        "values2 = [10, 25, 30]\n",
        "colors = ['skyblue', 'lightgreen', 'salmon']\n",
        "\n",
        "fig2 = go.Figure(data=[go.Bar(x=categories2, y=values2, marker_color=colors)])\n",
        "\n",
        "fig2.update_layout(\n",
        "    title='Colored Bar Plot',\n",
        "    xaxis_title='Groups',\n",
        "    yaxis_title='Counts'\n",
        ")\n",
        "\n",
        "fig2.show()\n",
        "\n",
        "#Example with horizontal bar chart\n",
        "fig3 = go.Figure(data=[go.Bar(y=categories, x=values, orientation='h')])\n",
        "\n",
        "fig3.update_layout(\n",
        "    title='Horizontal Bar Plot',\n",
        "    xaxis_title='Values',\n",
        "    yaxis_title='Categories'\n",
        ")\n",
        "\n",
        "fig3.show()\n",
        "\n",
        "#Example with text labels on bars\n",
        "fig4 = go.Figure(data=[go.Bar(x=categories, y=values, text=values, textposition='auto')])\n",
        "\n",
        "fig4.update_layout(\n",
        "    title='Bar plot with text labels',\n",
        "    xaxis_title='Categories',\n",
        "    yaxis_title='Values'\n",
        ")\n",
        "\n",
        "fig4.show()"
      ],
      "metadata": {
        "id": "EdQJEo73BuQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 Create a DataFrame and add a new column based on an existing column.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'col1': [1, 2, 3, 4, 5],\n",
        "        'col2': [10, 20, 30, 40, 50]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add a new column 'col3' that is 'col1' multiplied by 10\n",
        "df['col3'] = df['col1'] * 10\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(df)\n",
        "\n",
        "#Example with a conditional column\n",
        "df['col4'] = df['col1'].apply(lambda x: 'High' if x > 3 else 'Low')\n",
        "print(\"\\nDataFrame with conditional column:\")\n",
        "print(df)\n",
        "\n",
        "#Example with string operations\n",
        "data2 = {'Names': ['Alice', 'Bob', 'Charlie'],\n",
        "        'Initials': ['A.B', 'B.C', 'C.D']}\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "df2['First_Initial'] = df2['Initials'].str.split('.').str[0]\n",
        "\n",
        "print(\"\\nDataFrame with string column:\")\n",
        "print(df2)"
      ],
      "metadata": {
        "id": "bAtX68SCCORO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 Write a program to perform element-wise multiplication of two NumPy arrays.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def elementwise_multiply(array1, array2):\n",
        "  \"\"\"\n",
        "  Performs element-wise multiplication of two NumPy arrays.\n",
        "\n",
        "  Args:\n",
        "    array1: The first NumPy array.\n",
        "    array2: The second NumPy array.\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array containing the element-wise product, or None if the arrays\n",
        "    are not compatible for element-wise multiplication.\n",
        "  \"\"\"\n",
        "  if array1.shape != array2.shape:\n",
        "    print(\"Error: Arrays must have the same shape for element-wise multiplication.\")\n",
        "    return None\n",
        "\n",
        "  return array1 * array2\n",
        "\n",
        "# Example usage:\n",
        "array_a = np.array([1, 2, 3, 4])\n",
        "array_b = np.array([5, 6, 7, 8])\n",
        "\n",
        "result = elementwise_multiply(array_a, array_b)\n",
        "\n",
        "if result is not None:\n",
        "  print(\"Array 1:\", array_a)\n",
        "  print(\"Array 2:\", array_b)\n",
        "  print(\"Element-wise product:\", result)\n",
        "\n",
        "# Example with 2D arrays:\n",
        "array_c = np.array([[1, 2], [3, 4]])\n",
        "array_d = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "result_2d = elementwise_multiply(array_c, array_d)\n",
        "\n",
        "if result_2d is not None:\n",
        "  print(\"\\nArray C:\\n\", array_c)\n",
        "  print(\"Array D:\\n\", array_d)\n",
        "  print(\"Element-wise product:\\n\", result_2d)\n",
        "\n",
        "# Example with incompatible shapes:\n",
        "array_e = np.array([1, 2, 3])\n",
        "array_f = np.array([4, 5])\n",
        "\n",
        "result_incompatible = elementwise_multiply(array_e, array_f)"
      ],
      "metadata": {
        "id": "5y79R-3VDHwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Create a line plot with multiple lines using Matplotlib.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "x = np.linspace(0, 10, 100)  # 100 evenly spaced values from 0 to 10\n",
        "y1 = np.sin(x)\n",
        "y2 = np.cos(x)\n",
        "y3 = np.sin(x + np.pi/4) #shifted sin wave\n",
        "\n",
        "# Create the line plot\n",
        "plt.figure(figsize=(10, 6))  # Set figure size (optional)\n",
        "\n",
        "plt.plot(x, y1, label='sin(x)', linestyle='-', color='blue')\n",
        "plt.plot(x, y2, label='cos(x)', linestyle='--', color='red')\n",
        "plt.plot(x, y3, label='sin(x + pi/4)', linestyle=':', color='green')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Multiple Line Plot')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Add grid (optional)\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "#Example with different line widths and markers\n",
        "y4 = np.exp(-x/5) #exponential decay\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(x, y1, label = \"sin(x)\", linewidth = 2)\n",
        "plt.plot(x, y4, label = \"exp(-x/5)\", linewidth = 3, marker = 'o', markersize = 5)\n",
        "\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Line plots with different styles')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EpSKeESqD6ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "        'Age': [25, 30, 22, 35, 28],\n",
        "        'Score': [85, 92, 78, 95, 88]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Set a threshold\n",
        "threshold = 85\n",
        "\n",
        "# Filter rows where 'Score' is greater than the threshold\n",
        "filtered_df = df[df['Score'] > threshold]\n",
        "\n",
        "# Print the filtered DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nFiltered DataFrame (Score > {}):\".format(threshold))\n",
        "print(filtered_df)\n",
        "\n",
        "#Example with multiple filter conditions\n",
        "threshold_age = 25\n",
        "filtered_df2 = df[(df['Score'] > threshold) & (df['Age'] > threshold_age)]\n",
        "\n",
        "print(\"\\nFiltered DataFrame (Score > {} AND Age > {}):\".format(threshold, threshold_age))\n",
        "print(filtered_df2)\n",
        "\n",
        "#Example with string filtering.\n",
        "data2 = {'City': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney'],\n",
        "         'Population': [8398748, 8982000, 2140526, 13929286, 5312163]}\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "filtered_df3 = df2[df2['City'].str.startswith('T')]\n",
        "print(\"\\nFiltered DataFrame (City starts with 'T'):\")\n",
        "print(filtered_df3)\n",
        "\n",
        "#Example with numerical column filtering using numpy where.\n",
        "df['Pass'] = np.where(df['Score']>=80, True, False)\n",
        "print(\"\\nDataFrame with pass column:\")\n",
        "print(df)\n",
        "\n",
        "filtered_df4 = df[df['Pass']==True]\n",
        "print(\"\\nFiltered DataFrame (Pass == True):\")\n",
        "print(filtered_df4)"
      ],
      "metadata": {
        "id": "kT3OGD6aEYnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 Create a histogram using Seaborn to visualize a distribution.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate some sample data\n",
        "np.random.seed(0)\n",
        "data = np.random.normal(loc=50, scale=15, size=500)  # Normally distributed data\n",
        "\n",
        "# Create the histogram\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(data, bins=30, kde=True, color='skyblue')  # Create histogram with KDE\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Normally Distributed Data')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "#Example with different bin sizes and without KDE\n",
        "data2 = np.random.exponential(scale=20, size=500)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(data2, bins = 20, kde = False, color = 'salmon')\n",
        "plt.xlabel(\"Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Histogram of Exponentially Distributed Data\")\n",
        "plt.show()\n",
        "\n",
        "#Example with a rug plot\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(data, bins = 30, kde = True, color = 'lightgreen', rug=True)\n",
        "plt.xlabel(\"Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Histogram with Rug Plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Z9UCRNAE3Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11 Perform matrix multiplication using NumPy.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def matrix_multiply(matrix1, matrix2):\n",
        "  \"\"\"\n",
        "  Performs matrix multiplication of two NumPy matrices.\n",
        "\n",
        "  Args:\n",
        "    matrix1: The first NumPy matrix.\n",
        "    matrix2: The second NumPy matrix.\n",
        "\n",
        "  Returns:\n",
        "    The resulting NumPy matrix, or None if the matrices are not compatible\n",
        "    for multiplication.\n",
        "  \"\"\"\n",
        "  if matrix1.shape[1] != matrix2.shape[0]:\n",
        "    print(\"Error: Matrices are not compatible for multiplication.\")\n",
        "    print(f\"Matrix 1 shape: {matrix1.shape}\")\n",
        "    print(f\"Matrix 2 shape: {matrix2.shape}\")\n",
        "    return None\n",
        "\n",
        "  return np.matmul(matrix1, matrix2) # or matrix1 @ matrix2\n",
        "\n",
        "# Example usage:\n",
        "matrix_a = np.array([[1, 2],\n",
        "                     [3, 4]])\n",
        "\n",
        "matrix_b = np.array([[5, 6],\n",
        "                     [7, 8]])\n",
        "\n",
        "result = matrix_multiply(matrix_a, matrix_b)\n",
        "\n",
        "if result is not None:\n",
        "  print(\"Matrix A:\\n\", matrix_a)\n",
        "  print(\"Matrix B:\\n\", matrix_b)\n",
        "  print(\"Result of A * B:\\n\", result)\n",
        "\n",
        "# Example with matrices of different compatible dimensions\n",
        "matrix_c = np.array([[1, 2, 3],\n",
        "                     [4, 5, 6]])\n",
        "\n",
        "matrix_d = np.array([[7, 8],\n",
        "                     [9, 10],\n",
        "                     [11, 12]])\n",
        "\n",
        "result2 = matrix_multiply(matrix_c, matrix_d)\n",
        "\n",
        "if result2 is not None:\n",
        "  print(\"\\nMatrix C:\\n\", matrix_c)\n",
        "  print(\"Matrix D:\\n\", matrix_d)\n",
        "  print(\"Result of C * D:\\n\", result2)\n",
        "\n",
        "#Example of incompatible matrices.\n",
        "matrix_e = np.array([[1,2], [3,4]])\n",
        "matrix_f = np.array([[5,6,7], [8,9,10]])\n",
        "\n",
        "result3 = matrix_multiply(matrix_e, matrix_f)"
      ],
      "metadata": {
        "id": "5S5n86eDFd_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12 Use Pandas to load a CSV file and display its first 5 rows.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def display_first_5_rows(file_path):\n",
        "  \"\"\"\n",
        "  Loads a CSV file using Pandas and displays its first 5 rows.\n",
        "\n",
        "  Args:\n",
        "    file_path: The path to the CSV file.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(df.head())  # Display the first 5 rows\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage (replace 'your_file.csv' with the actual file path):\n",
        "display_first_5_rows('your_file.csv') #make sure the file exists in the same directory, or use the full path.\n",
        "\n",
        "#Example with a different number of rows.\n",
        "def display_rows(file_path, num_rows):\n",
        "    \"\"\"\n",
        "    Loads a CSV file using Pandas and displays the specified number of rows.\n",
        "\n",
        "    Args:\n",
        "        file_path: The path to the CSV file.\n",
        "        num_rows: The number of rows to display.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(df.head(num_rows))\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "display_rows('your_file.csv', 10) #Display the first 10 rows.\n",
        "\n",
        "#Example with a file with a different separator.\n",
        "def display_rows_sep(file_path, separator):\n",
        "    \"\"\"\n",
        "    Loads a CSV file using Pandas and displays the first 5 rows, using a specified separator.\n",
        "\n",
        "    Args:\n",
        "        file_path: The path to the CSV file.\n",
        "        separator: The separator used in the file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, sep = separator)\n",
        "        print(df.head())\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "display_rows_sep('your_file.tsv', '\\t') #example with a tab separated file."
      ],
      "metadata": {
        "id": "MOKtoS3nF8_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13 Create a 3D scatter plot using Plotly.\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# Generate sample 3D data\n",
        "np.random.seed(0)\n",
        "n_points = 100\n",
        "x = np.random.randn(n_points)\n",
        "y = np.random.randn(n_points)\n",
        "z = np.random.randn(n_points)\n",
        "\n",
        "# Create the 3D scatter plot\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "    x=x,\n",
        "    y=y,\n",
        "    z=z,\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=5,\n",
        "        color=z,                # color based on z value\n",
        "        colorscale='Viridis',   # choose a colorscale\n",
        "        opacity=0.8\n",
        "    )\n",
        ")])\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    margin=dict(l=0, r=0, b=0, t=0), #reduce margins\n",
        "    scene=dict(\n",
        "        xaxis=dict(title='X Axis'),\n",
        "        yaxis=dict(title='Y Axis'),\n",
        "        zaxis=dict(title='Z Axis')\n",
        "    ),\n",
        "    title='3D Scatter Plot'\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "#Example with different marker sizes and colors\n",
        "n_points2 = 50\n",
        "x2 = np.random.randn(n_points2) * 2\n",
        "y2 = np.random.randn(n_points2) * 2\n",
        "z2 = np.random.randn(n_points2) * 2\n",
        "\n",
        "fig2 = go.Figure(data=[go.Scatter3d(\n",
        "    x=x2,\n",
        "    y=y2,\n",
        "    z=z2,\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        size=8,\n",
        "        color='red',\n",
        "        opacity=0.6,\n",
        "        symbol='diamond'\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig2.update_layout(\n",
        "    title='3D Scatter Plot with Custom Markers',\n",
        "    scene=dict(\n",
        "        xaxis=dict(title='X'),\n",
        "        yaxis=dict(title='Y'),\n",
        "        zaxis=dict(title='Z')\n",
        "    )\n",
        ")\n",
        "\n",
        "fig2.show()\n",
        "\n",
        "#Example with a surface\n",
        "x3 = np.linspace(-5, 5, 50)\n",
        "y3 = np.linspace(-5, 5, 50)\n",
        "x3, y3 = np.meshgrid(x3, y3)\n",
        "z3 = np.sin(np.sqrt(x3**2 + y3**2))\n",
        "\n",
        "fig3 = go.Figure(data=[go.Surface(x=x3, y=y3, z=z3)])\n",
        "\n",
        "fig3.update_layout(\n",
        "    title='3D Surface Plot',\n",
        "    scene=dict(\n",
        "        xaxis=dict(title='X'),\n",
        "        yaxis=dict(title='Y'),\n",
        "        zaxis=dict(title='Z')\n",
        "    )\n",
        ")\n",
        "\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "MzIFeGIrGYxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}